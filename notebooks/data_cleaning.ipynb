{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cfde502d",
   "metadata": {},
   "source": [
    "## üßº Wildlife Collision Data Cleaning Notebook\n",
    "\n",
    "Goal: Clean, structure and enrich the raw wildlife collision dataset for ML model training and analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9cca450f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Loaded 635851 rows from 10 files\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------------\n",
    "#  1. Import libraries and load Excel files\n",
    "# -------------------------------------\n",
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "# Load all original Excel files (ignore header rows, mark source file)\n",
    "files = glob.glob(\"../data/original_excels/*.xlsx\")\n",
    "dfs = []\n",
    "for file in files:\n",
    "    df = pd.read_excel(file, skiprows=6)\n",
    "    df[\"Source_File\"] = file\n",
    "    dfs.append(df)\n",
    "\n",
    "# Combine all Excel sheets into one dataframe\n",
    "all_data = pd.concat(dfs, ignore_index=True)\n",
    "print(f\"‚úÖ Loaded {len(all_data)} rows from {len(files)} files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af091e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------\n",
    "#  2. Save raw combined data\n",
    "# -------------------------------------\n",
    "all_data.to_csv(\"../data/raw_collision_data.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "437ff984",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßπ Cleaned column names:\n",
      "['DjurId', 'OlycksId', 'Kalla', 'Typ_av_olycka', 'Datum', 'Tid', '√Ör', 'Manad', 'Dag_pa_aret', 'Unnamed:_9', 'Unnamed:_10', 'Veckodag', 'Lan', 'Unnamed:_13', 'Kommun', 'Viltslag', 'Lat_WGS84', 'Long_WGS84', 'Lat_RT90', 'Long_RT90', 'Kon', '√Örsunge', 'Vad_har_skett_med_viltet', 'Source_File']\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------------\n",
    "#  3. Clean column names\n",
    "# -------------------------------------\n",
    "all_data.columns = (\n",
    "    all_data.columns\n",
    "    .str.strip()\n",
    "    .str.replace(\" \", \"_\")\n",
    "    .str.replace(\"√•\", \"a\")\n",
    "    .str.replace(\"√§\", \"a\")\n",
    "    .str.replace(\"√∂\", \"o\")\n",
    ")\n",
    "\n",
    "print(\"üßπ Cleaned column names:\")\n",
    "print(all_data.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de85543c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÖ Extracted time features\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------------\n",
    "# 4. Convert date fields and extract components\n",
    "# -------------------------------------\n",
    "# Convert date columns\n",
    "all_data[\"Datum\"] = pd.to_datetime(all_data[\"Datum\"], errors=\"coerce\")\n",
    "all_data[\"Tid\"] = pd.to_datetime(all_data[\"Tid\"], errors=\"coerce\", format=\"%H:%M\")\n",
    "\n",
    "# Extract time-based features\n",
    "all_data[\"Manad\"] = all_data[\"Datum\"].dt.month\n",
    "all_data[\"Veckodag\"] = all_data[\"Datum\"].dt.day_name()\n",
    "all_data[\"Ar\"] = all_data[\"Datum\"].dt.year\n",
    "all_data[\"Dag_pa_aret\"] = all_data[\"Datum\"].dt.dayofyear\n",
    "\n",
    "print(\"üìÖ Extracted time features\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9cf22ca6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üóëÔ∏è Dropped unused columns\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------------\n",
    "# 5. Drop unnecessary columns\n",
    "# -------------------------------------\n",
    "cols_to_drop = [\"Unnamed:_9\", \"Unnamed:_10\", \"Unnamed:_13\", \"Source_File\"]\n",
    "for col in cols_to_drop:\n",
    "    if col in all_data.columns:\n",
    "        all_data = all_data.drop(columns=[col])\n",
    "\n",
    "print(\"üóëÔ∏è Dropped unused columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "52a5293f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üåç Translated values to English\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------------\n",
    "# 6. Translate categorical values to English\n",
    "# -------------------------------------\n",
    "\n",
    "# Species\n",
    "species_translation = {\n",
    "    \"Alg\": \"Moose\", \"Radjur\": \"Roe Deer\", \"Vildsvin\": \"Wild Boar\",\n",
    "    \"Dovhjort\": \"Fallow Deer\", \"Kronhjort\": \"Red Deer\", \"Bjorn\": \"Brown Bear\",\n",
    "    \"Lodjur\": \"Lynx\", \"J√§rv\": \"Wolverine\", \"Ovriga_djur\": \"Other\", \"Okant\": \"Unknown\"\n",
    "}\n",
    "\n",
    "# Sex\n",
    "sex_translation = {\"Hane\": \"Male\", \"Hona\": \"Female\", \"Okant\": \"Unknown\"}\n",
    "\n",
    "# Juvenile\n",
    "juvenile_translation = {\"Ja\": \"Yes\", \"Nej\": \"No\", \"Okant\": \"Unknown\"}\n",
    "\n",
    "# Fate\n",
    "fate_translation = {\n",
    "    \"Avlivat\": \"Euthanized\", \"Dott_pa_olycksplatsen\": \"Dead at crash site\",\n",
    "    \"Ej_patraffat\": \"Not found\", \"Bedoms_oskadad\": \"Assumed unharmed\",\n",
    "    \"Patraffat_dott\": \"Found dead\", \"Okant\": \"Unknown\"\n",
    "}\n",
    "\n",
    "# Apply translations\n",
    "all_data[\"Species\"] = all_data[\"Viltslag\"].map(species_translation)\n",
    "all_data[\"Sex\"] = all_data[\"Kon\"].map(sex_translation)\n",
    "all_data[\"Juvenile\"] = all_data[\"√Örsunge\"].map(juvenile_translation)\n",
    "all_data[\"Animal_Outcome\"] = all_data[\"Vad_har_skett_med_viltet\"].map(fate_translation)\n",
    "\n",
    "# Drop original Swedish columns\n",
    "all_data = all_data.drop(columns=[\"Viltslag\", \"Kon\", \"√Örsunge\", \"Vad_har_skett_med_viltet\"])\n",
    "\n",
    "print(\"üåç Translated values to English\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0cfaa2a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Columns renamed and mapped\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------------\n",
    "# 7. Rename columns to English\n",
    "# -------------------------------------\n",
    "column_rename = {\n",
    "    \"DjurId\": \"Animal_ID\", \"OlycksId\": \"Collision_ID\", \"Kalla\": \"Source\",\n",
    "    \"Typ_av_olycka\": \"Type_of_Collision\", \"Datum\": \"Date\", \"Tid\": \"Time\",\n",
    "    \"Ar\": \"Year\", \"Manad\": \"Month\", \"Dag_pa_aret\": \"Day_of_Year\", \"Veckodag\": \"Weekday\",\n",
    "    \"Lan\": \"County\", \"Kommun\": \"Municipality\",\n",
    "    \"Lat_WGS84\": \"Lat_WGS84\", \"Long_WGS84\": \"Long_WGS84\",\n",
    "    \"Lat_RT90\": \"Lat_RT90\", \"Long_RT90\": \"Long_RT90\"\n",
    "}\n",
    "\n",
    "source_translation = {\n",
    "    \"Jagarrapporterad_olycka_(viltolycka.se)\": \"Hunter-reported collision (viltolycka.se)\",\n",
    "    \"Polisrapporterad_olycka_(viltolycka.se)\": \"Police-reported collision (viltolycka.se)\"\n",
    "}\n",
    "\n",
    "collision_type_translation = {\n",
    "    \"Vag\": \"Road\", \"Jarnvag\": \"Railway\"\n",
    "}\n",
    "\n",
    "# Rename and map\n",
    "all_data = all_data.rename(columns=column_rename)\n",
    "all_data[\"Source\"] = all_data[\"Source\"].map(source_translation).fillna(all_data[\"Source\"])\n",
    "all_data[\"Type_of_Collision\"] = all_data[\"Type_of_Collision\"].map(collision_type_translation).fillna(all_data[\"Type_of_Collision\"])\n",
    "\n",
    "print(\"‚úÖ Columns renamed and mapped\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5212f478",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ Saved cleaned data to cleaned_data.csv\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------------\n",
    "# 8. Save cleaned dataset\n",
    "# -------------------------------------\n",
    "all_data.to_csv(\"../data/cleaned_data.csv\", index=False)\n",
    "print(\"üíæ Saved cleaned data to cleaned_data.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
